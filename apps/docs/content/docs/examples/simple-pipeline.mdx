---
title: Simple Pipeline
description: Chain plugins for data processing workflows
---

## Basic Pipeline

Chain source, transformer, and distributor plugins:

```typescript
import { createPluginRuntime, PluginRuntime } from "every-plugin/runtime";
import { Effect } from "effect";

const runtime = createPluginRuntime({
  registry: {
    "social-feed": {
      remoteUrl: "https://cdn.example.com/plugins/social/remoteEntry.js",
      type: "source",
      version: "1.0.0"
    },
    "content-filter": {
      remoteUrl: "https://cdn.example.com/plugins/filter/remoteEntry.js",
      type: "transformer",
      version: "1.0.0"
    },
    "email-sender": {
      remoteUrl: "https://cdn.example.com/plugins/email/remoteEntry.js",
      type: "distributor",
      version: "1.0.0"
    }
  },
  secrets: {
    SOCIAL_API_KEY: process.env.SOCIAL_API_KEY!,
    SMTP_PASSWORD: process.env.SMTP_PASSWORD!
  }
});

const pipeline = Effect.gen(function* () {
  const pluginRuntime = yield* PluginRuntime;
  
  // 1. Fetch data from social media
  const sourcePlugin = yield* pluginRuntime.usePlugin("social-feed", {
    secrets: { apiKey: "{{SOCIAL_API_KEY}}" },
    variables: { timeout: 30000 }
  });
  
  const rawData = yield* pluginRuntime.executePlugin(sourcePlugin, {
    procedure: "search",
    input: { query: "typescript", limit: 50 },
    state: null
  });
  
  console.log(`Fetched ${rawData.items.length} posts`);
  
  // 2. Filter content
  const filterPlugin = yield* pluginRuntime.usePlugin("content-filter", {
    variables: { 
      minScore: 0.7,
      blockedKeywords: ["spam", "advertisement"]
    }
  });
  
  const filteredData = yield* pluginRuntime.executePlugin(filterPlugin, {
    items: rawData.items
  });
  
  console.log(`Filtered to ${filteredData.items.length} quality posts`);
  
  // 3. Send via email
  const emailPlugin = yield* pluginRuntime.usePlugin("email-sender", {
    secrets: { smtpPassword: "{{SMTP_PASSWORD}}" },
    variables: {
      to: "admin@example.com",
      subject: "Daily TypeScript Posts"
    }
  });
  
  const emailResult = yield* pluginRuntime.executePlugin(emailPlugin, {
    items: filteredData.items
  });
  
  return {
    fetched: rawData.items.length,
    filtered: filteredData.items.length,
    sent: emailResult.sent
  };
});

const result = await runtime.runPromise(pipeline);
console.log("Pipeline completed:", result);
await runtime.disposeRuntime();
```

## Error Handling Pipeline

Add resilience with fallbacks:

```typescript
const resilientPipeline = Effect.gen(function* () {
  const pluginRuntime = yield* PluginRuntime;
  
  // Try primary source, fallback to secondary
  const rawData = yield* pluginRuntime.executePlugin(primarySource, input).pipe(
    Effect.catchAll(() => 
      pluginRuntime.executePlugin(secondarySource, input)
    ),
    Effect.catchAll(() => 
      Effect.succeed({ items: [] }) // Empty fallback
    )
  );
  
  if (rawData.items.length === 0) {
    console.log("No data available, skipping pipeline");
    return { processed: 0 };
  }
  
  // Process with retry
  const processed = yield* pluginRuntime.executePlugin(processor, {
    items: rawData.items
  }).pipe(
    Effect.retry({ times: 3 }),
    Effect.catchAll((error) => {
      console.error("Processing failed:", error);
      return Effect.succeed({ items: [] });
    })
  );
  
  return { processed: processed.items.length };
});
```

## Batch Processing Pipeline

Handle large datasets efficiently:

```typescript
const batchPipeline = Effect.gen(function* () {
  const pluginRuntime = yield* PluginRuntime;
  const BATCH_SIZE = 100;
  
  // Fetch all data
  const sourcePlugin = yield* pluginRuntime.usePlugin("data-source", config);
  const allData = yield* pluginRuntime.executePlugin(sourcePlugin, {
    procedure: "fetchAll",
    input: { dataset: "large-dataset" },
    state: null
  });
  
  console.log(`Processing ${allData.items.length} items in batches of ${BATCH_SIZE}`);
  
  // Process in batches
  const processor = yield* pluginRuntime.usePlugin("batch-processor", {
    variables: { batchSize: BATCH_SIZE }
  });
  
  const batches = [];
  for (let i = 0; i < allData.items.length; i += BATCH_SIZE) {
    batches.push(allData.items.slice(i, i + BATCH_SIZE));
  }
  
  const results = yield* Effect.all(
    batches.map((batch, index) =>
      Effect.gen(function* () {
        console.log(`Processing batch ${index + 1}/${batches.length}`);
        return yield* pluginRuntime.executePlugin(processor, {
          items: batch
        });
      }).pipe(
        Effect.catchAll((error) => {
          console.error(`Batch ${index + 1} failed:`, error);
          return Effect.succeed({ items: [] });
        })
      )
    ),
    { concurrency: 3 } // Process 3 batches concurrently
  );
  
  const totalProcessed = results.reduce((sum, result) => sum + result.items.length, 0);
  console.log(`Processed ${totalProcessed} items total`);
  
  return { totalProcessed };
});
```

## Conditional Pipeline

Route data based on content:

```typescript
const conditionalPipeline = Effect.gen(function* () {
  const pluginRuntime = yield* PluginRuntime;
  
  // Fetch and classify data
  const sourceData = yield* pluginRuntime.executePlugin(sourcePlugin, input);
  const classifier = yield* pluginRuntime.usePlugin("content-classifier", config);
  
  const classified = yield* pluginRuntime.executePlugin(classifier, {
    items: sourceData.items
  });
  
  // Route based on classification
  const urgent = classified.items.filter(item => item.category === "urgent");
  const normal = classified.items.filter(item => item.category === "normal");
  const archive = classified.items.filter(item => item.category === "archive");
  
  console.log(`Routing: ${urgent.length} urgent, ${normal.length} normal, ${archive.length} archive`);
  
  // Process each category differently
  const results = yield* Effect.all([
    // Urgent items - immediate processing
    urgent.length > 0 
      ? pluginRuntime.executePlugin(urgentProcessor, { items: urgent })
      : Effect.succeed({ processed: 0 }),
    
    // Normal items - standard processing  
    normal.length > 0
      ? pluginRuntime.executePlugin(normalProcessor, { items: normal })
      : Effect.succeed({ processed: 0 }),
    
    // Archive items - batch processing
    archive.length > 0
      ? pluginRuntime.executePlugin(archiveProcessor, { items: archive })
      : Effect.succeed({ processed: 0 })
  ]);
  
  return {
    urgent: results[0].processed,
    normal: results[1].processed,
    archived: results[2].processed
  };
});
```

## Worker Pipeline

Integrate with job queues:

```typescript
import { Job, Worker } from "bullmq";

const worker = new Worker("data-pipeline", async (job: Job) => {
  const { sourceConfig, processorConfig, outputConfig } = job.data;
  
  return runtime.runPromise(
    Effect.gen(function* () {
      const pluginRuntime = yield* PluginRuntime;
      
      // Dynamic plugin loading based on job data
      const source = yield* pluginRuntime.usePlugin(job.data.sourcePlugin, sourceConfig);
      const processor = yield* pluginRuntime.usePlugin(job.data.processorPlugin, processorConfig);
      const output = yield* pluginRuntime.usePlugin(job.data.outputPlugin, outputConfig);
      
      // Execute pipeline
      const rawData = yield* pluginRuntime.executePlugin(source, job.data.sourceInput);
      const processed = yield* pluginRuntime.executePlugin(processor, { items: rawData.items });
      const result = yield* pluginRuntime.executePlugin(output, { items: processed.items });
      
      return {
        jobId: job.id,
        processed: processed.items.length,
        output: result.sent || result.stored || result.processed
      };
    }).pipe(
      Effect.catchAll((error) => {
        console.error(`Job ${job.id} failed:`, error);
        throw error; // Let BullMQ handle retries
      })
    )
  );
});

// Cleanup on shutdown
process.on("SIGTERM", async () => {
  await worker.close();
  await runtime.disposeRuntime();
});
```

These patterns show how to compose plugins into powerful data processing workflows.
