---
title: Multi-plugin Flows
description: Advanced patterns for combining multiple plugins and streams
---

## Stream-to-Pipeline Flow

Process streaming data through multiple plugin pipelines:

```typescript
import { Effect, Stream } from "effect";

const streamToPipeline = Effect.gen(function* () {
  const pluginRuntime = yield* PluginRuntime;

  // Create source stream
  const sourceStream = yield* pluginRuntime.streamPlugin(
    "live-data-feed",
    {
      secrets: { apiKey: "{{FEED_API_KEY}}" },
      variables: { timeout: 30000 }
    },
    {
      procedure: "monitor",
      input: { categories: ["urgent", "breaking"] },
      state: null
    },
    { maxItems: 500 }
  );

  // Initialize pipeline plugins
  const enricher = yield* pluginRuntime.usePlugin("data-enricher", {
    secrets: { enrichmentKey: "{{ENRICHMENT_KEY}}" }
  });

  const analyzer = yield* pluginRuntime.usePlugin("sentiment-analyzer", {
    secrets: { aiKey: "{{AI_API_KEY}}" }
  });

  const distributor = yield* pluginRuntime.usePlugin("multi-channel-distributor", {
    secrets: { 
      slackWebhook: "{{SLACK_WEBHOOK}}",
      emailPassword: "{{EMAIL_PASSWORD}}"
    },
    variables: { channels: ["slack", "email", "webhook"] }
  });

  // Process stream through pipeline
  return yield* sourceStream.pipe(
    // Batch items for efficient processing
    Stream.grouped(10),
    
    // Process each batch through pipeline
    Stream.mapEffect((batch) =>
      Effect.gen(function* () {
        const batchArray = Array.from(batch);
        
        // Stage 1: Enrich data
        const enriched = yield* pluginRuntime.executePlugin(enricher, {
          items: batchArray
        });

        // Stage 2: Analyze sentiment
        const analyzed = yield* pluginRuntime.executePlugin(analyzer, {
          items: enriched.items
        });

        // Stage 3: Distribute based on sentiment
        const highPriority = analyzed.items.filter(item => item.sentiment < -0.5 || item.urgency > 0.8);
        
        if (highPriority.length > 0) {
          yield* pluginRuntime.executePlugin(distributor, {
            items: highPriority
          });
        }

        return analyzed.items;
      }).pipe(
        Effect.catchAll((error) => {
          console.error("Batch processing failed:", error);
          return Effect.succeed([]);
        })
      )
    ),
    
    // Flatten results
    Stream.flatMap((items) => Stream.fromIterable(items)),
    Stream.runCollect
  );
});
```

## Parallel Multi-Source Processing

Process multiple sources in parallel and merge results:

```typescript
const parallelMultiSource = Effect.gen(function* () {
  const pluginRuntime = yield* PluginRuntime;

  // Define source configurations
  const sources = [
    { id: "twitter-feed", config: twitterConfig, input: twitterInput },
    { id: "reddit-feed", config: redditConfig, input: redditInput },
    { id: "news-api", config: newsConfig, input: newsInput },
    { id: "rss-aggregator", config: rssConfig, input: rssInput }
  ];

  // Process all sources in parallel
  const sourceResults = yield* Effect.all(
    sources.map(({ id, config, input }) =>
      Effect.gen(function* () {
        console.log(`Starting ${id}...`);
        
        const stream = yield* pluginRuntime.streamPlugin(
          id, config, input, { maxItems: 200, stopWhenEmpty: true }
        );

        const items = yield* stream.pipe(
          Stream.map(item => ({ ...item, source: id })),
          Stream.runCollect
        );

        console.log(`${id}: ${items.length} items`);
        return Array.from(items);
      }).pipe(
        Effect.catchAll((error) => {
          console.error(`${id} failed:`, error);
          return Effect.succeed([]);
        })
      )
    ),
    { concurrency: 4 } // Process all sources concurrently
  );

  // Merge and deduplicate
  const allItems = sourceResults.flat();
  const deduplicator = yield* pluginRuntime.usePlugin("deduplicator", {
    variables: { similarityThreshold: 0.85 }
  });

  const deduplicated = yield* pluginRuntime.executePlugin(deduplicator, {
    items: allItems
  });

  console.log(`Merged ${allItems.length} items, deduplicated to ${deduplicated.items.length}`);

  // Process through shared pipeline
  const processor = yield* pluginRuntime.usePlugin("content-processor", {
    variables: { outputFormat: "standardized" }
  });

  const processed = yield* pluginRuntime.executePlugin(processor, {
    items: deduplicated.items
  });

  return processed.items;
});
```

## Dynamic Plugin Selection

Select plugins dynamically based on data characteristics:

```typescript
const dynamicPluginSelection = Effect.gen(function* () {
  const pluginRuntime = yield* PluginRuntime;

  // Get data stream
  const dataStream = yield* pluginRuntime.streamPlugin(
    "mixed-content-feed", config, input, { maxItems: 1000 }
  );

  // Plugin selection logic
  const selectProcessor = (item: any) => {
    if (item.type === "image") return "image-processor";
    if (item.type === "video") return "video-processor";
    if (item.type === "text") return "text-processor";
    if (item.type === "audio") return "audio-processor";
    return "generic-processor";
  };

  const selectDistributor = (item: any) => {
    if (item.priority === "urgent") return "instant-distributor";
    if (item.category === "social") return "social-distributor";
    if (item.category === "news") return "news-distributor";
    return "standard-distributor";
  };

  // Process with dynamic plugin selection
  return yield* dataStream.pipe(
    Stream.mapEffect((item) =>
      Effect.gen(function* () {
        // Select and use processor
        const processorId = selectProcessor(item);
        const processor = yield* pluginRuntime.usePlugin(processorId, getProcessorConfig(processorId));
        
        const processed = yield* pluginRuntime.executePlugin(processor, {
          items: [item]
        });

        if (processed.items.length === 0) return null;

        const processedItem = processed.items[0];

        // Select and use distributor
        const distributorId = selectDistributor(processedItem);
        const distributor = yield* pluginRuntime.usePlugin(distributorId, getDistributorConfig(distributorId));

        yield* pluginRuntime.executePlugin(distributor, {
          items: [processedItem]
        });

        return processedItem;
      }).pipe(
        Effect.catchAll((error) => {
          console.error("Dynamic processing failed:", error);
          return Effect.succeed(null);
        })
      )
    ),
    Stream.filter((item) => item !== null),
    Stream.runCollect
  );
});

const getProcessorConfig = (processorId: string) => {
  const configs = {
    "image-processor": { variables: { format: "webp", quality: 80 } },
    "video-processor": { variables: { codec: "h264", bitrate: "1000k" } },
    "text-processor": { variables: { maxLength: 1000, language: "en" } },
    "audio-processor": { variables: { format: "mp3", bitrate: "128k" } },
    "generic-processor": { variables: { mode: "standard" } }
  };
  return configs[processorId as keyof typeof configs] || {};
};
```

## Conditional Branching Flow

Branch processing based on data analysis:

```typescript
const conditionalBranching = Effect.gen(function* () {
  const pluginRuntime = yield* PluginRuntime;

  // Initial data processing
  const sourceData = yield* pluginRuntime.executePlugin(sourcePlugin, input);
  
  // Analyze data to determine processing path
  const analyzer = yield* pluginRuntime.usePlugin("content-analyzer", {
    variables: { analysisDepth: "full" }
  });

  const analysis = yield* pluginRuntime.executePlugin(analyzer, {
    items: sourceData.items
  });

  // Branch based on analysis results
  const branches = {
    highValue: analysis.items.filter(item => item.value > 0.8),
    mediumValue: analysis.items.filter(item => item.value > 0.5 && item.value <= 0.8),
    lowValue: analysis.items.filter(item => item.value <= 0.5),
    urgent: analysis.items.filter(item => item.urgency > 0.9)
  };

  console.log("Branching:", {
    highValue: branches.highValue.length,
    mediumValue: branches.mediumValue.length,
    lowValue: branches.lowValue.length,
    urgent: branches.urgent.length
  });

  // Process each branch with different strategies
  const results = yield* Effect.all([
    // High value: Premium processing
    branches.highValue.length > 0
      ? Effect.gen(function* () {
          const premiumProcessor = yield* pluginRuntime.usePlugin("premium-processor", {
            variables: { quality: "highest", features: ["ai-enhancement", "metadata-extraction"] }
          });
          
          const premiumDistributor = yield* pluginRuntime.usePlugin("premium-distributor", {
            secrets: { premiumApiKey: "{{PREMIUM_API_KEY}}" }
          });

          const processed = yield* pluginRuntime.executePlugin(premiumProcessor, {
            items: branches.highValue
          });

          yield* pluginRuntime.executePlugin(premiumDistributor, {
            items: processed.items
          });

          return { branch: "highValue", processed: processed.items.length };
        })
      : Effect.succeed({ branch: "highValue", processed: 0 }),

    // Medium value: Standard processing
    branches.mediumValue.length > 0
      ? Effect.gen(function* () {
          const standardProcessor = yield* pluginRuntime.usePlugin("standard-processor", {
            variables: { quality: "standard" }
          });

          const processed = yield* pluginRuntime.executePlugin(standardProcessor, {
            items: branches.mediumValue
          });

          return { branch: "mediumValue", processed: processed.items.length };
        })
      : Effect.succeed({ branch: "mediumValue", processed: 0 }),

    // Low value: Batch processing
    branches.lowValue.length > 0
      ? Effect.gen(function* () {
          const batchProcessor = yield* pluginRuntime.usePlugin("batch-processor", {
            variables: { batchSize: 100, quality: "basic" }
          });

          const processed = yield* pluginRuntime.executePlugin(batchProcessor, {
            items: branches.lowValue
          });

          return { branch: "lowValue", processed: processed.items.length };
        })
      : Effect.succeed({ branch: "lowValue", processed: 0 }),

    // Urgent: Immediate processing
    branches.urgent.length > 0
      ? Effect.gen(function* () {
          const urgentProcessor = yield* pluginRuntime.usePlugin("urgent-processor", {
            variables: { priority: "immediate" }
          });

          const urgentDistributor = yield* pluginRuntime.usePlugin("alert-distributor", {
            secrets: { alertWebhook: "{{ALERT_WEBHOOK}}" }
          });

          const processed = yield* pluginRuntime.executePlugin(urgentProcessor, {
            items: branches.urgent
          });

          yield* pluginRuntime.executePlugin(urgentDistributor, {
            items: processed.items
          });

          return { branch: "urgent", processed: processed.items.length };
        })
      : Effect.succeed({ branch: "urgent", processed: 0 })
  ]);

  return {
    totalAnalyzed: analysis.items.length,
    branchResults: results,
    totalProcessed: results.reduce((sum, r) => sum + r.processed, 0)
  };
});
```

## Plugin Chain Orchestration

Orchestrate complex plugin chains with dependency management:

```typescript
const pluginChainOrchestration = Effect.gen(function* () {
  const pluginRuntime = yield* PluginRuntime;

  // Define processing chain with dependencies
  const processingChain = [
    {
      stage: "ingestion",
      plugins: ["data-ingester", "format-validator"],
      parallel: true
    },
    {
      stage: "preprocessing", 
      plugins: ["data-cleaner", "normalizer"],
      parallel: true,
      dependsOn: ["ingestion"]
    },
    {
      stage: "analysis",
      plugins: ["content-analyzer", "sentiment-analyzer", "category-classifier"],
      parallel: true,
      dependsOn: ["preprocessing"]
    },
    {
      stage: "enrichment",
      plugins: ["metadata-enricher"],
      parallel: false,
      dependsOn: ["analysis"]
    },
    {
      stage: "distribution",
      plugins: ["primary-distributor", "backup-distributor"],
      parallel: false,
      dependsOn: ["enrichment"]
    }
  ];

  let currentData = sourceData.items;
  const stageResults = new Map<string, any>();

  // Execute stages in order
  for (const stage of processingChain) {
    console.log(`Executing stage: ${stage.stage}`);

    if (stage.parallel) {
      // Execute plugins in parallel
      const results = yield* Effect.all(
        stage.plugins.map(pluginId =>
          Effect.gen(function* () {
            const plugin = yield* pluginRuntime.usePlugin(pluginId, getStageConfig(stage.stage, pluginId));
            return yield* pluginRuntime.executePlugin(plugin, { items: currentData });
          }).pipe(
            Effect.catchAll((error) => {
              console.error(`Plugin ${pluginId} failed:`, error);
              return Effect.succeed({ items: [] });
            })
          )
        ),
        { concurrency: stage.plugins.length }
      );

      // Merge results from parallel execution
      currentData = results.flatMap(r => r.items);
    } else {
      // Execute plugins sequentially
      for (const pluginId of stage.plugins) {
        const plugin = yield* pluginRuntime.usePlugin(pluginId, getStageConfig(stage.stage, pluginId));
        const result = yield* pluginRuntime.executePlugin(plugin, { items: currentData }).pipe(
          Effect.catchAll((error) => {
            console.error(`Plugin ${pluginId} failed:`, error);
            return Effect.succeed({ items: currentData }); // Continue with previous data
          })
        );
        currentData = result.items;
      }
    }

    stageResults.set(stage.stage, {
      itemCount: currentData.length,
      plugins: stage.plugins,
      parallel: stage.parallel
    });

    console.log(`Stage ${stage.stage} completed: ${currentData.length} items`);
  }

  return {
    finalItems: currentData,
    stageResults: Object.fromEntries(stageResults),
    totalStages: processingChain.length
  };
});

const getStageConfig = (stage: string, pluginId: string) => {
  // Return stage and plugin specific configuration
  const configs = {
    ingestion: {
      "data-ingester": { variables: { batchSize: 1000 } },
      "format-validator": { variables: { strictMode: true } }
    },
    preprocessing: {
      "data-cleaner": { variables: { removeEmpty: true, trimWhitespace: true } },
      "normalizer": { variables: { encoding: "utf-8" } }
    },
    analysis: {
      "content-analyzer": { variables: { depth: "full" } },
      "sentiment-analyzer": { secrets: { aiKey: "{{AI_API_KEY}}" } },
      "category-classifier": { variables: { categories: ["tech", "business", "other"] } }
    },
    enrichment: {
      "metadata-enricher": { secrets: { enrichmentKey: "{{ENRICHMENT_KEY}}" } }
    },
    distribution: {
      "primary-distributor": { secrets: { apiKey: "{{PRIMARY_API_KEY}}" } },
      "backup-distributor": { secrets: { apiKey: "{{BACKUP_API_KEY}}" } }
    }
  };

  return configs[stage as keyof typeof configs]?.[pluginId] || {};
};
```

These patterns demonstrate sophisticated multi-plugin orchestration for complex data processing workflows.
