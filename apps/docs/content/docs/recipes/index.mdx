---
title: Recipes
description: Advanced patterns and examples for every-plugin
---

This guide provides advanced patterns and real-world examples for building sophisticated plugins.

## Real-time Event Broadcasting

Create plugins that broadcast events to multiple clients using MemoryPublisher pub/sub semantics:

```typescript
import { createPlugin } from "every-plugin";
import { Effect } from "every-plugin/effect";
import { oc, eventIterator, MemoryPublisher } from "every-plugin/orpc";
import { z } from "every-plugin/zod";

// Define event types for broadcasting
type BroadcastEvents = {
  'notifications': {
    id: string;
    type: string;
    message: string;
    timestamp: number;
  };
};

const NotificationSchema = z.object({
  id: z.string(),
  type: z.string(),
  message: z.string(),
  timestamp: z.number()
});

const contract = oc.router({
  // Subscribe to real-time notifications
  subscribeNotifications: oc
    .route({ method: 'POST', path: '/subscribe/notifications' })
    .input(z.object({
      types: z.array(z.string()).optional(),
      lastEventId: z.string().optional()
    }))
    .output(eventIterator(NotificationSchema)),

  // Publish a notification manually
  publishNotification: oc
    .route({ method: 'POST', path: '/publish/notification' })
    .input(z.object({
      type: z.string(),
      message: z.string()
    }))
    .output(z.object({ published: z.boolean() }))
});

export default createPlugin({
  id: "notification-service",
  contract,
  variables: z.object({
    enabled: z.boolean().default(true)
  }),
  secrets: z.object({ apiKey: z.string() }),

  initialize: (config) => Effect.gen(function* () {
    // Create publisher for real-time broadcasting
    const publisher = new MemoryPublisher<BroadcastEvents>({
      resumeRetentionSeconds: 60 * 2 // Support serverless resume for 2 minutes
    });

    // Start background producer (optional)
    if (config.variables.enabled) {
      yield* Effect.forkScoped(
        Effect.gen(function* () {
          while (true) {
            // Simulate receiving notifications from external source
            const notification = {
              id: `notif-${Date.now()}`,
              type: 'system',
              message: `System update at ${new Date().toISOString()}`,
              timestamp: Date.now()
            };

            // Publish to ALL subscribers (broadcast semantics)
            yield* Effect.tryPromise(() =>
              publisher.publish('notifications', notification)
            ).pipe(
              Effect.catchAll((error) => {
                console.log('Notification publish failed:', error);
                return Effect.void;
              })
            );

            yield* Effect.sleep("30 seconds");
          }
        })
      );
    }

    return { publisher };
  }),

  createRouter: (context, builder) => ({
    subscribeNotifications: builder.subscribeNotifications.handler(async function* ({ input, signal }) {
      // Subscribe to broadcast stream with resume support
      const iterator = context.publisher.subscribe('notifications', {
        signal,
        lastEventId: input.lastEventId
      });

      for await (const event of iterator) {
        // Filter by type if specified
        if (input.types && !input.types.includes(event.type)) {
          continue;
        }
        yield event;
      }
    }),

    publishNotification: builder.publishNotification.handler(async ({ input }) => {
      const notification = {
        id: `manual-${Date.now()}`,
        type: input.type,
        message: input.message,
        timestamp: Date.now()
      };

      await context.publisher.publish('notifications', notification);
      return { published: true };
    })
  })
});
```

**Key Benefits:**
- **Broadcast Semantics**: All connected clients get the same events
- **Resume Support**: Clients can reconnect after serverless timeouts using `lastEventId`
- **Real-time**: Multiple clients streaming simultaneously
- **Scalable**: Drop-in replacement with Redis publishers for multi-instance deployments

## Stream Processing Pipeline

Chain multiple plugins for data transformation:

```typescript
// Source plugin streams raw data
const { client: source } = await runtime.usePlugin("data-source", {
  secrets: { apiKey: "{{SOURCE_API_KEY}}" }
});

// Transformer plugin processes data
const { client: transformer } = await runtime.usePlugin("transformer", {
  variables: { format: "json", validate: true }
});

// Distributor plugin sends to destinations
const { client: distributor } = await runtime.usePlugin("distributor", {
  secrets: { webhook: "{{WEBHOOK_URL}}" }
});

// Stream through pipeline
const stream = await source.streamData({ query: "realtime" });

for await (const item of stream) {
  try {
    // Transform
    const transformed = await transformer.transform({ 
      data: item 
    });
    
    // Distribute
    await distributor.send({ 
      items: [transformed] 
    });
  } catch (error) {
    console.error("Pipeline error:", error);
  }
}
```

## Batch Processing

Process items in batches for efficiency:

```typescript
async function processBatch(items: any[]) {
  const { client } = await runtime.usePlugin("batch-processor", {
    variables: { batchSize: 10 }
  });
  
  return await client.processBatch({ items });
}

// Stream with batching
const stream = await source.streamData({ query: "large-dataset" });

let batch: any[] = [];
const results: any[] = [];

for await (const item of stream) {
  batch.push(item);
  
  if (batch.length >= 10) {
    console.log(`Processing batch of ${batch.length} items`);
    const processed = await processBatch(batch);
    results.push(...processed.items);
    batch = [];
  }
}

// Process remaining items
if (batch.length > 0) {
  const processed = await processBatch(batch);
  results.push(...processed.items);
}

console.log(`Total processed: ${results.length}`);
```

## Rate Limiting

Implement rate limiting in plugin handlers:

```typescript
import { RateLimiter } from 'limiter';

export default createPlugin({
  id: "rate-limited-api",
  contract,
  variables: z.object({
    requestsPerSecond: z.number().default(10)
  }),
  secrets: z.object({ apiKey: z.string() }),
  
  initialize: (config) => Effect.gen(function* () {
    const limiter = new RateLimiter({
      tokensPerInterval: config.variables.requestsPerSecond,
      interval: 'second'
    });
    
    const service = new ApiService(config.secrets.apiKey);
    
    return { service, limiter };
  }),
  
  createRouter: (context, builder) => ({
    getData: builder.getData.handler(async ({ input, errors }) => {
      // Wait for rate limit token
      const hasToken = await context.limiter.removeTokens(1);
      
      if (!hasToken) {
        throw errors.RATE_LIMITED({
          message: "Rate limit exceeded",
          data: {
            retryAfter: 1,
            remainingRequests: 0,
            limitType: 'requests' as const
          }
        });
      }
      
      try {
        const data = await Effect.runPromise(
          context.service.getData(input.id)
        );
        return { data };
      } catch (error) {
        throw errors.SERVICE_UNAVAILABLE({
          message: "Service unavailable",
          data: { retryAfter: 5 }
        });
      }
    })
  })
});
```

## Retry Logic

Implement exponential backoff for retries:

```typescript
async function fetchWithRetry(
  client: any,
  input: any,
  maxRetries = 3
) {
  let lastError: Error | null = null;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await client.getData(input);
    } catch (error: any) {
      lastError = error;
      
      // Don't retry on auth errors
      if (error.code === "UNAUTHORIZED") {
        throw error;
      }
      
      // Extract retry-after from error
      const retryAfter = error.data?.retryAfter || Math.pow(2, attempt);
      
      console.log(`Retry ${attempt + 1}/${maxRetries} after ${retryAfter}s`);
      
      if (attempt < maxRetries - 1) {
        await new Promise(resolve => 
          setTimeout(resolve, retryAfter * 1000)
        );
      }
    }
  }
  
  throw lastError;
}

// Usage
const { client } = await runtime.usePlugin("unreliable-api", config);
const result = await fetchWithRetry(client, { id: "123" });
```

## Caching Layer

Add caching to reduce API calls:

```typescript
import { LRUCache } from 'lru-cache';

export default createPlugin({
  id: "cached-api",
  contract,
  variables: z.object({
    cacheMaxSize: z.number().default(1000),
    cacheTtlMs: z.number().default(60000)
  }),
  secrets: z.object({ apiKey: z.string() }),
  
  initialize: (config) => Effect.gen(function* () {
    const cache = new LRUCache({
      max: config.variables.cacheMaxSize,
      ttl: config.variables.cacheTtlMs
    });
    
    const service = new ApiService(config.secrets.apiKey);
    
    return { service, cache };
  }),
  
  createRouter: (context, builder) => ({
    getData: builder.getData.handler(async ({ input }) => {
      const cacheKey = `data:${input.id}`;
      
      // Check cache
      const cached = context.cache.get(cacheKey);
      if (cached) {
        console.log(`Cache hit: ${cacheKey}`);
        return { data: cached };
      }
      
      // Fetch from API
      console.log(`Cache miss: ${cacheKey}`);
      const data = await Effect.runPromise(
        context.service.getData(input.id)
      );
      
      // Store in cache
      context.cache.set(cacheKey, data);
      
      return { data };
    })
  })
});
```

## Queue Integration

Integrate with job queues like BullMQ:

```typescript
import { Queue, Worker, Job } from 'bullmq';
import { createPluginRuntime } from 'every-plugin/runtime';

// Initialize runtime once
const runtime = createPluginRuntime({
  registry: await loadRegistry(),
  secrets: await loadSecrets()
});

// Create queue
const pluginQueue = new Queue('plugin-jobs', {
  connection: { host: 'localhost', port: 6379 }
});

// Add jobs to queue
await pluginQueue.add('process-data', {
  pluginId: 'data-processor',
  config: {
    secrets: { apiKey: '{{API_KEY}}' },
    variables: { format: 'json' }
  },
  input: { id: '123' }
});

// Worker to process jobs
const worker = new Worker(
  'plugin-jobs',
  async (job: Job) => {
    const { pluginId, config, input } = job.data;
    
    console.log(`Processing job ${job.id} with ${pluginId}`);
    
    try {
      const { client } = await runtime.usePlugin(pluginId, config);
      const result = await client.process(input);
      return result;
    } catch (error) {
      console.error(`Job ${job.id} failed:`, error);
      throw error;
    }
  },
  { connection: { host: 'localhost', port: 6379 } }
);

// Cleanup on shutdown
process.on('SIGTERM', async () => {
  await worker.close();
  await runtime.shutdown();
  process.exit(0);
});
```

## Multi-Tenant Plugin

Support multiple tenants with isolated contexts:

```typescript
export default createPlugin({
  id: "multi-tenant-api",
  contract,
  variables: z.object({
    tenantId: z.string()
  }),
  secrets: z.object({
    masterApiKey: z.string()
  }),
  
  initialize: (config) => Effect.gen(function* () {
    // Create tenant-specific service
    const service = new TenantService(
      config.secrets.masterApiKey,
      config.variables.tenantId
    );
    
    // Verify tenant access
    yield* Effect.tryPromise({
      try: () => service.verifyTenant(),
      catch: () => new Error("Invalid tenant")
    });
    
    return { service, tenantId: config.variables.tenantId };
  }),
  
  createRouter: (context, builder) => ({
    getData: builder.getData.handler(async ({ input }) => {
      // All operations scoped to tenant
      const data = await Effect.runPromise(
        context.service.getData(input.id)
      );
      
      return {
        data,
        tenantId: context.tenantId
      };
    })
  })
});

// Usage with different tenants
const { client: tenant1 } = await runtime.usePlugin("multi-tenant-api", {
  secrets: { masterApiKey: "{{MASTER_API_KEY}}" },
  variables: { tenantId: "tenant-1" }
});

const { client: tenant2 } = await runtime.usePlugin("multi-tenant-api", {
  secrets: { masterApiKey: "{{MASTER_API_KEY}}" },
  variables: { tenantId: "tenant-2" }
});
```

## Health Checks

Implement health checks for monitoring:

```typescript
const contract = oc.router({
  health: oc.route({ method: 'GET', path: '/health' })
    .input(z.object({}))
    .output(z.object({
      status: z.enum(['healthy', 'degraded', 'unhealthy']),
      checks: z.record(z.boolean()),
      timestamp: z.number()
    })),
  
  // ... other procedures
});

export default createPlugin({
  id: "monitored-api",
  contract,
  // ...
  
  createRouter: (context, builder) => ({
    health: builder.health.handler(async () => {
      const checks: Record<string, boolean> = {};
      
      // Check API connectivity
      try {
        await fetch('https://api.example.com/health');
        checks.api = true;
      } catch {
        checks.api = false;
      }
      
      // Check cache
      checks.cache = context.cache !== undefined;
      
      // Check queue
      try {
        checks.queue = !(await Effect.runPromise(
          Queue.isShutdown(context.queue)
        ));
      } catch {
        checks.queue = false;
      }
      
      const allHealthy = Object.values(checks).every(Boolean);
      const someHealthy = Object.values(checks).some(Boolean);
      
      return {
        status: allHealthy ? 'healthy' : someHealthy ? 'degraded' : 'unhealthy',
        checks,
        timestamp: Date.now()
      };
    }),
    
    // ... other handlers
  })
});
```

## Graceful Shutdown

Handle graceful shutdown with cleanup:

```typescript
const runtime = createPluginRuntime({
  registry: await loadRegistry(),
  secrets: await loadSecrets()
});

// Track active operations
const activeOperations = new Set<Promise<any>>();

async function executeWithTracking(operation: Promise<any>) {
  activeOperations.add(operation);
  try {
    return await operation;
  } finally {
    activeOperations.delete(operation);
  }
}

// Graceful shutdown handler
async function shutdown() {
  console.log('Shutting down gracefully...');
  
  // Wait for active operations
  console.log(`Waiting for ${activeOperations.size} operations...`);
  await Promise.allSettled(activeOperations);
  
  // Shutdown runtime
  await runtime.shutdown();
  
  console.log('Shutdown complete');
  process.exit(0);
}

process.on('SIGTERM', shutdown);
process.on('SIGINT', shutdown);

// Usage
const { client } = await runtime.usePlugin("my-plugin", config);
await executeWithTracking(client.getData({ id: "123" }));
```

## Serverless-Ready Event Streams

Design event streams that can resume after serverless timeouts using `lastEventId` and `resumeRetentionSeconds`:

```typescript
import { createPlugin } from "every-plugin";
import { Effect } from "every-plugin/effect";
import { oc, eventIterator, IORedisPublisher } from "every-plugin/orpc";
import { z } from "every-plugin/zod";

type ActivityEvents = {
  'user-activity': {
    id: string;
    userId: string;
    action: string;
    timestamp: number;
    metadata: Record<string, any>;
  };
};

const contract = oc.router({
  streamActivity: oc
    .route({ method: 'POST', path: '/stream/activity' })
    .input(z.object({
      userId: z.string().optional(),
      lastEventId: z.string().optional(),
      timeoutSec: z.number().default(300)
    }))
    .output(eventIterator(z.object({
      id: z.string(),
      userId: z.string(),
      action: z.string(),
      timestamp: z.number(),
      metadata: z.record(z.any())
    })))
});

export default createPlugin({
  id: "user-activity-stream",
  contract,
  variables: z.object({
    redisUrl: z.string().optional(), // For multi-instance scaling
    resumeRetentionSeconds: z.number().default(300) // 5 minutes
  }),
  secrets: z.object({ activitySecret: z.string() }),

  initialize: (config) => Effect.gen(function* () {
    // Use Redis publisher for distributed deployments
    let publisher: any;
    if (config.variables.redisUrl) {
      const Redis = require('ioredis');
      const redis = new Redis(config.variables.redisUrl);
      publisher = new IORedisPublisher<ActivityEvents>(redis, {
        resumeRetentionSeconds: config.variables.resumeRetentionSeconds
      });
    } else {
      // Fallback to in-memory for development
      const { MemoryPublisher } = require('@orpc/experimental-publisher/memory');
      publisher = new MemoryPublisher<ActivityEvents>({
        resumeRetentionSeconds: config.variables.resumeRetentionSeconds
      });
    }

    // Background activity simulator
    yield* Effect.forkScoped(
      Effect.gen(function* () {
        let eventId = 0;
        while (true) {
          eventId++;
          const activity = {
            id: `activity-${eventId}`,
            userId: `user-${eventId % 100}`,
            action: ['login', 'click', 'purchase'][eventId % 3],
            timestamp: Date.now(),
            metadata: { sessionId: `session-${eventId}` }
          };

          yield* Effect.tryPromise(() =>
            publisher.publish('user-activity', activity)
          ).pipe(
            Effect.catchAll((error) => {
              console.log('Activity publish failed:', error);
              return Effect.void;
            })
          );

          yield* Effect.sleep("5 seconds");
        }
      })
    );

    return { publisher };
  }),

  createRouter: (context, builder) => ({
    streamActivity: builder.streamActivity.handler(async function* ({ input, signal }) {
      // Set up abort signal for timeout
      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
      }, input.timeoutSec * 1000);

      signal?.addEventListener('abort', () => {
        clearTimeout(timeoutId);
        controller.abort();
      });

      try {
        const iterator = context.publisher.subscribe('user-activity', {
          signal,
          lastEventId: input.lastEventId
        });

        for await (const event of iterator) {
          // Filter by user if specified
          if (input.userId && event.userId !== input.userId) {
            continue;
          }

          // Check if timeout exceeded
          if (controller.signal.aborted) {
            break;
          }

          yield event;
        }
      } finally {
        clearTimeout(timeoutId);
      }
    })
  })
});
```

**Client-side Resume Logic:**

```typescript
// Client maintains lastEventId for resuming
let lastEventId: string | undefined;

async function streamActivities(config: any) {
  const { client } = await runtime.usePlugin("user-activity-stream");

  while (true) {
    try {
      const stream = await client.streamActivity({
        lastEventId, // Resume from last received event
        timeoutSec: 300
      });

      for await (const event of stream) {
        console.log('Activity:', event);
        lastEventId = event.id; // Update last received

        // Process event...
        await processActivity(event);
      }

    } catch (error) {
      if (error.name === 'AbortError') {
        console.log('Stream timed out, resuming in 5 seconds...');
        await new Promise(resolve => setTimeout(resolve, 5000));
        continue; // Retry with lastEventId
      }

      throw error; // Non-timeout error
    }
  }
}
```

## Accessing Event Metadata

Event streams can include optional metadata for debugging, monitoring, and advanced use cases. Use `getEventMeta()` to access Server-Sent Events metadata from streaming responses:

```typescript
import { getEventMeta } from "every-plugin/orpc";

// In your streaming handler or consumer
for await (const event of stream) {
  // Access optional event metadata
  const meta = getEventMeta(event);

  // Metadata includes: id, retry, comments
  if (meta) {
    if (meta.id) console.log(`Event ID: ${meta.id}`);           // Correlation/tracking
    if (meta.retry) console.log(`Retry delay: ${meta.retry}ms`); // Connection health
    if (meta.comments?.length) console.log(`Comments: ${meta.comments}`);
  }

  // Process your event data
  console.log('Event data:', event);
}
```

**Metadata Fields:**
- **`id`**: Unique event identifier for correlation tracking and resume tokens
- **`retry`**: Milliseconds to wait before retrying if connection fails
- **`comments`**: Array of comment strings, often used for SSE debugging information

**Practical Use Cases:**

*Monitoring Connection Health:*
```typescript
const stream = await client.streamEvents({ lastEventId });

let lastEventTime = Date.now();
for await (const event of stream) {
  const meta = getEventMeta(event);

  if (meta?.id) {
    console.log(`[${new Date().toISOString()}] Event ${meta.id} received`);
    lastEventTime = Date.now();
  }

  // Monitor for stale connections
  const timeSinceLastEvent = Date.now() - lastEventTime;
  if (timeSinceLastEvent > 30000) { // 30 seconds
    console.warn('Stream appears stale, might need reconnection');
  }

  processEvent(event);
}
```

*Debugging Stream Quality:*
```typescript
let retryCount = 0;
const stream = await client.streamEvents();

for await (const event of stream) {
  const meta = getEventMeta(event);

  // Track retry rates as connection quality indicator
  if (meta?.retry && meta.retry > 1000) { // Slow retry suggests issues
    retryCount++;
    console.warn(`High retry delay detected: ${meta.retry}ms (count: ${retryCount})`);
  }

  // Log SSE comments for debugging
  if (meta?.comments?.length) {
    console.debug('SSE Comments:', meta.comments);
  }
}
```

**Note:** Metadata access is optional and primarily useful for debugging, monitoring, or advanced stream management. Most streaming use cases don't need to access these fields directly.

## Scaling with Redis Publishers

Deploy the same plugin across multiple instances using Redis publishers:

```typescript
import { IORedisPublisher } from 'every-plugin/orpc';
import Redis from 'ioredis';

// In production initialization
initialize: (config) => Effect.gen(function* () {
  // Connect to Redis for inter-instance coordination
  const redis = new Redis(process.env.REDIS_URL);

  // Redis publisher shares events across all instances
  const publisher = new IORedisPublisher<BroadcastEvents>(redis, {
    resumeRetentionSeconds: 60 * 2,
    namespace: 'my-plugin' // Avoid conflicts with other plugins
  });

  // Background tasks run on ANY instance
  // Events are broadcast to ALL connected clients regardless of instance
  yield* Effect.forkScoped(
    Effect.gen(function* () {
      while (true) {
        const event = yield* fetchFromExternalAPI();

        // Publish to Redis - available to all instances
        yield* Effect.tryPromise(() =>
          publisher.publish('channel', event)
        );

        yield* Effect.sleep("30 seconds");
      }
    })
  );

  return { publisher, redis };
}),

// Clean up Redis on shutdown
shutdown: (context) => Effect.gen(function* () {
  yield* Effect.tryPromise({
    try: () => context.redis.quit(),
    catch: () => Effect.void
  });
})
```

**Benefits:**
- **Horizontal Scaling**: Load balance across multiple server instances
- **Fault Tolerance**: If one instance goes down, others continue streaming
- **Shared State**: Events are consistent across all client connections

## Work Distribution with Queues

Use queues for work distribution when each task should be processed exactly once:

```typescript
import { createPlugin } from "every-plugin";
import { Effect, Queue } from "every-plugin/effect";
import { oc } from "every-plugin/orpc";
import { z } from "every-plugin/zod";

const contract = oc.router({
  // Enqueue work to be processed exactly once
  enqueueWork: oc
    .route({ method: 'POST', path: '/enqueue' })
    .input(z.object({
      taskId: z.string(),
      priority: z.number().default(1),
      payload: z.any()
    }))
    .output(z.object({ enqueued: z.boolean() })),

  // Get queue statistics
  getQueueStats: oc
    .route({ method: 'GET', path: '/stats' })
    .output(z.object({
      pending: z.number(),
      processing: z.number(),
      completed: z.number()
    }))
});

export default createPlugin({
  id: "work-processor",
  contract,
  variables: z.object({
    workerCount: z.number().default(3),
    maxConcurrency: z.number().default(10)
  }),
  secrets: {},

  initialize: (config) => Effect.gen(function* () {
    // Bounded queue for task distribution
    const taskQueue = yield* Effect.acquireRelease(
      Queue.bounded(config.variables.maxConcurrency),
      (q) => Queue.shutdown(q)
    );

    // Statistics tracking
    const stats = {
      pending: 0,
      processing: 0,
      completed: 0
    };

    // Start multiple workers - each takes one task (work distribution)
    for (let i = 0; i < config.variables.workerCount; i++) {
      yield* Effect.forkScoped(
        Effect.gen(function* () {
          while (true) {
            try {
              stats.processing++;
              // Take ONE task from queue (exactly once semantics)
              const task = yield* Queue.take(taskQueue);
              stats.pending--;

              // Process task
              yield* processTask(task);

              stats.completed++;
              stats.processing--;

            } catch (error) {
              console.error(`Worker ${i} error:`, error);
              stats.processing--;
            }
          }
        })
      );
    }

    return { taskQueue, stats };
  }),

  createRouter: (context, builder) => ({
    enqueueWork: builder.enqueueWork.handler(async ({ input }) => {
      // Add to queue for distribution to ONE worker
      await Effect.runPromise(
        Queue.offer(context.taskQueue, {
          id: input.taskId,
          priority: input.priority,
          payload: input.payload,
          enqueuedAt: Date.now()
        })
      );

      context.stats.pending++;
      return { enqueued: true };
    }),

    getQueueStats: builder.getQueueStats.handler(async () => {
      return {
        pending: context.stats.pending,
        processing: context.stats.processing,
        completed: context.stats.completed
      };
    })
  })
});
```

**When to Use Queues vs Publishers:**

| Pattern | Use Case | Semantics | Example |
|---------|---------|-----------|---------|
| **MemoryPublisher** | Broadcasting events to multiple clients | Pub/sub - all subscribers get events | Real-time notifications, activity feeds |
| **Queue** | Distributing work to workers | Work distribution - each task processed once | Job processing, task queues |

## Next Steps

<Cards>
  <Card title="Creating Plugins" href="/docs/creating-plugins">
    Build your own plugins
  </Card>
  <Card title="Testing" href="/docs/testing">
    Test advanced patterns
  </Card>
  <Card title="Deployment" href="/docs/creating-plugins/deployment">
    Deploy to production
  </Card>
</Cards>
